{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5a320f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cfc843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357067ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(X, y, format = '-', label=''):\n",
    "    plt.plot(X, y, format, label=label)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(True)\n",
    "np.random.seed(0)\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()\n",
    "\n",
    "experiment_name = \"xray_image_dataset\"\n",
    "method = \"tff_training\"\n",
    "this_dir = Path.cwd()\n",
    "model_dir = this_dir / \"saved_models\" / experiment_name / method\n",
    "output_dir = this_dir / \"results\" / experiment_name / method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de8b4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5144 images belonging to 3 classes.\n",
      "Found 1288 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data generators\n",
    "train_dir='./../Data/archive/Data/train/'\n",
    "validation_dir='./../Data/archive/Data/test/'\n",
    "batch_size=10\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen =  ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        # Since we use categorical_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0373636b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c4cd7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 150, 150, 3) (510, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store the data in X_train, y_train variables by iterating over the batches\n",
    "train_generator.reset()\n",
    "X_train, y_train = next(train_generator)\n",
    "for i in tqdm(range(int(len(train_generator)/batch_size)-1)): #1st batch is already fetched before the for loop.\n",
    "    img, label = next(train_generator)\n",
    "    X_train = np.append(X_train, img, axis=0 )\n",
    "    y_train = np.append(y_train, label, axis=0)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31bb8b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:01<00:00,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 150, 150, 3) (120, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validation_generator.reset()\n",
    "X_test, y_test = next(validation_generator)\n",
    "for i in tqdm(range(int(len(validation_generator)/batch_size)-1)): #1st batch is already fetched before the for loop.\n",
    "    img, label = next(validation_generator)\n",
    "    X_test = np.append(X_test, img, axis=0 )\n",
    "    y_test = np.append(y_test, label, axis=0)\n",
    "    \n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36cf6bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.astype(np.float32).reshape(360, 150, 150, 1)\n",
    "y_test = y_test.astype(np.int32).reshape(360, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d520686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b500037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split=4 #Number of clients \n",
    "total_image_count = len(X_train)\n",
    "image_per_set = int(np.floor(total_image_count/split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca923e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding data from 0 to 127 for client : client_1\n",
      "Adding data from 127 to 254 for client : client_2\n",
      "Adding data from 254 to 381 for client : client_3\n",
      "Adding data from 381 to 508 for client : client_4\n"
     ]
    }
   ],
   "source": [
    "client_train_dataset = collections.OrderedDict()\n",
    "for i in range(1, split+1):\n",
    "    client_name = \"client_\" + str(i)\n",
    "    start = image_per_set * (i-1)\n",
    "    end = image_per_set * i\n",
    "\n",
    "    print(f\"Adding data from {start} to {end} for client : {client_name}\")\n",
    "    data = collections.OrderedDict((('label', y_train[start:end]), ('pixels', X_train[start:end])))\n",
    "    client_train_dataset[client_name] = data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5236313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(None, 150, 150, 3)\n",
      "(None, 150, 150, 3)\n",
      "(None, 150, 150, 3)\n",
      "(None, 150, 150, 3)\n",
      "(None, 150, 150, 3)\n",
      "Number of client datasets: 4\n",
      "First dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 150, 150, 1)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import reshape, nest, config\n",
    "NUM_EPOCHS=5\n",
    "BATCH_SIZE=10\n",
    "PREFETCH_BUFFER = 10\n",
    "\n",
    "print(len(client_train_dataset))\n",
    "\n",
    "\n",
    "train_dataset = tff.simulation.FromTensorSlicesClientData(client_train_dataset)\n",
    "\n",
    "sample_dataset = train_dataset.create_tf_dataset_for_client(train_dataset.client_ids[0])\n",
    "#print(sample_dataset['pixels'])\n",
    "sample_element = next(iter(sample_dataset))\n",
    "\n",
    "SHUFFLE_BUFFER = image_per_set\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "    def batch_format_fn(element):\n",
    "        \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
    "        print(element['pixels'].get_shape())\n",
    "        return collections.OrderedDict(\n",
    "            x=reshape(element['pixels'], [-1, 150, 150, 1]),\n",
    "            y=reshape(element['label'], [-1, 1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
    "        BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
    "        \n",
    "\n",
    "preprocessed_sample_dataset = preprocess(sample_dataset)\n",
    "sample_batch = nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_sample_dataset)))\n",
    "\n",
    "\n",
    "def make_federated_data(client_data, client_ids):\n",
    "    return [preprocess(client_data.create_tf_dataset_for_client(x)) for x in client_ids]\n",
    "\n",
    "federated_train_data = make_federated_data(train_dataset, train_dataset.client_ids)\n",
    "\n",
    "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
    "print('First dataset: {d}'.format(d=federated_train_data[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f43a0d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "\n",
    "def create_keras_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0161fdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <model=<trainable=<float32[3,3,1,32],float32[32],float32[3,3,32,64],float32[64],float32[82944,512],float32[512],float32[512,10],float32[10]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import reshape, nest, config\n",
    "from tensorflow.keras import losses, metrics, optimizers\n",
    "import tensorflow_federated as tff\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "method = \"tff_training\"\n",
    "client_lr = 1e-2\n",
    "server_lr = 1e-2\n",
    "NUM_ROUNDS = 10\n",
    "\n",
    "\n",
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=preprocessed_sample_dataset.element_spec,\n",
    "      loss=losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "\n",
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: optimizers.Adam(learning_rate=client_lr),\n",
    "    server_optimizer_fn=lambda: optimizers.SGD(learning_rate=server_lr))\n",
    "\n",
    "print(str(iterative_process.initialize.type_signature))\n",
    "\n",
    "state = iterative_process.initialize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d15fc1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tff_train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6680/714684558.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtff_train_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtff_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtff_val_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mev_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m metric_collection = {\"sparse_categorical_accuracy\": tff_train_acc,\n\u001b[0;32m      5\u001b[0m                      \u001b[1;34m\"val_sparse_categorical_accuracy\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtff_val_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tff_train_loss' is not defined"
     ]
    }
   ],
   "source": [
    "tff_train_loss.append(float(tff_metrics.loss))\n",
    "tff_val_loss.append(ev_result[0])\n",
    "\n",
    "metric_collection = {\"sparse_categorical_accuracy\": tff_train_acc,\n",
    "                     \"val_sparse_categorical_accuracy\": tff_val_acc,\n",
    "                     \"loss\": tff_train_loss,\n",
    "                     \"val_loss\": tff_val_loss}\n",
    "\n",
    "#if eval_model:\n",
    "#    eval_model.save(model_dir / (experiment_name + \".h5\"))\n",
    "#else:\n",
    "#    print(\"training didn't started\")\n",
    "#    exit()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plot_graph(list(range(1, 51))[4::5], tff_train_acc, label='Train Accuracy')\n",
    "plot_graph(list(range(1, 51))[4::5], tff_val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(output_dir / \"federated_model_Accuracy.png\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_graph(list(range(1, 51))[4::5], tff_train_loss, label='Train loss')\n",
    "plot_graph(list(range(1, 51))[4::5], tff_val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(output_dir / \"federated_model_loss.png\")\n",
    "\n",
    "\n",
    "\n",
    "# saving metric values to text file\n",
    "\n",
    "txt_file_path = output_dir / (experiment_name + \".txt\")\n",
    "with open(txt_file_path.as_posix(), \"w\") as handle:\n",
    "    content = []\n",
    "    for key, val in metric_collection.items():\n",
    "        line_content = key\n",
    "        val = [str(k) for k in val]\n",
    "        line_content = line_content + \" \" + \" \".join(val)\n",
    "        content.append(line_content)\n",
    "    handle.write(\"\\n\".join(content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39cce856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5144 images belonging to 3 classes.\n",
      "Found 1288 images belonging to 3 classes.\n",
      "2.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 32, 32, 3) (510, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 32, 32, 3) (120, 3)\n",
      "Adding data from 0 to 127 for client : client_1\n",
      "Adding data from 127 to 254 for client : client_2\n",
      "Adding data from 254 to 381 for client : client_3\n",
      "Adding data from 381 to 508 for client : client_4\n",
      "4\n",
      "(None, 32, 32, 3)\n",
      "(None, 32, 32, 3)\n",
      "(None, 32, 32, 3)\n",
      "(None, 32, 32, 3)\n",
      "(None, 32, 32, 3)\n",
      "Number of client datasets: 4\n",
      "First dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 32, 32, 1)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>\n",
      "( -> <model=<trainable=<float32[3,3,1,32],float32[32],float32[7200,512],float32[512],float32[512,3],float32[3]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_federated.python.learning' has no attribute 'set_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6680/3590616975.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;31m#     tff.learning.assign_weights_to_keras_model(eval_model, state.model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0mtff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[0mev_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_federated.python.learning' has no attribute 'set_weights'"
     ]
    }
   ],
   "source": [
    "# @Author: sreedevic\n",
    "# @Date:   2021-11-08T10:20:45+00:00\n",
    "# @Last modified by:   sreedevic\n",
    "# @Last modified time: 2021-11-08T22:44:17+00:00\n",
    "\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graph(X, y, format = '-', label=''):\n",
    "    plt.plot(X, y, format, label=label)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(True)\n",
    "np.random.seed(0)\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()\n",
    "\n",
    "experiment_name = \"xray_image_dataset\"\n",
    "method = \"tff_training\"\n",
    "this_dir = Path.cwd()\n",
    "model_dir = this_dir / \"saved_models\" / experiment_name / method\n",
    "output_dir = this_dir / \"results\" / experiment_name / method\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data generators\n",
    "train_dir='./../Data/archive/Data/train/'\n",
    "validation_dir='./../Data/archive/Data/test/'\n",
    "batch_size=10\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen =  ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 32x32\n",
    "        target_size=(32, 32),\n",
    "        batch_size=batch_size,\n",
    "        # Since we use categorical_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(32, 32),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "train_generator.class_indices.values()\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "import tensorflow as tf; print(tf.__version__)\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "# Store the data in X_train, y_train variables by iterating over the batches\n",
    "train_generator.reset()\n",
    "X_train, y_train = next(train_generator)\n",
    "for i in tqdm(range(int(len(train_generator)/batch_size)-1)): #1st batch is already fetched before the for loop.\n",
    "    img, label = next(train_generator)\n",
    "    X_train = np.append(X_train, img, axis=0 )\n",
    "    y_train = np.append(y_train, label, axis=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "validation_generator.reset()\n",
    "X_test, y_test = next(validation_generator)\n",
    "for i in tqdm(range(int(len(validation_generator)/batch_size)-1)): #1st batch is already fetched before the for loop.\n",
    "    img, label = next(validation_generator)\n",
    "    X_test = np.append(X_test, img, axis=0 )\n",
    "    y_test = np.append(y_test, label, axis=0)\n",
    "\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "X_test = X_test.astype(np.float32).reshape(360, 32, 32, 1)\n",
    "y_test = y_test.astype(np.int32).reshape(360, 1)\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "len(train_generator)\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.int32)\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "split=4 #Number of clients\n",
    "total_image_count = len(X_train)\n",
    "image_per_set = int(np.floor(total_image_count/split))\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "client_train_dataset = collections.OrderedDict()\n",
    "for i in range(1, split+1):\n",
    "    client_name = \"client_\" + str(i)\n",
    "    start = image_per_set * (i-1)\n",
    "    end = image_per_set * i\n",
    "\n",
    "    print(f\"Adding data from {start} to {end} for client : {client_name}\")\n",
    "    data = collections.OrderedDict((('label', y_train[start:end]), ('pixels', X_train[start:end])))\n",
    "    client_train_dataset[client_name] = data\n",
    "\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "from tensorflow import reshape, nest, config\n",
    "NUM_EPOCHS=5\n",
    "BATCH_SIZE=10\n",
    "PREFETCH_BUFFER = 10\n",
    "\n",
    "print(len(client_train_dataset))\n",
    "\n",
    "\n",
    "train_dataset = tff.simulation.FromTensorSlicesClientData(client_train_dataset)\n",
    "\n",
    "sample_dataset = train_dataset.create_tf_dataset_for_client(train_dataset.client_ids[0])\n",
    "#print(sample_dataset['pixels'])\n",
    "sample_element = next(iter(sample_dataset))\n",
    "\n",
    "SHUFFLE_BUFFER = image_per_set\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "    def batch_format_fn(element):\n",
    "        \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
    "        print(element['pixels'].get_shape())\n",
    "        return collections.OrderedDict(\n",
    "            x=reshape(element['pixels'], [-1, 32, 32, 1]),\n",
    "            y=reshape(element['label'], [-1, 1]))\n",
    "\n",
    "\n",
    "\n",
    "    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
    "        BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
    "\n",
    "\n",
    "preprocessed_sample_dataset = preprocess(sample_dataset)\n",
    "sample_batch = nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_sample_dataset)))\n",
    "\n",
    "\n",
    "def make_federated_data(client_data, client_ids):\n",
    "    return [preprocess(client_data.create_tf_dataset_for_client(x)) for x in client_ids]\n",
    "\n",
    "federated_train_data = make_federated_data(train_dataset, train_dataset.client_ids)\n",
    "\n",
    "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
    "print('First dataset: {d}'.format(d=federated_train_data[0]))\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "def create_keras_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
    "        #MaxPool2D(pool_size=(2, 2)),\n",
    "        #Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(3, activation='softmax')\n",
    "\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import reshape, nest, config\n",
    "from tensorflow.keras import losses, metrics, optimizers\n",
    "import tensorflow_federated as tff\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "method = \"tff_training\"\n",
    "client_lr = 1e-2\n",
    "server_lr = 1e-2\n",
    "NUM_ROUNDS = 10\n",
    "\n",
    "\n",
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=preprocessed_sample_dataset.element_spec,\n",
    "      loss=losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "\n",
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: optimizers.Adam(learning_rate=client_lr),\n",
    "    server_optimizer_fn=lambda: optimizers.SGD(learning_rate=server_lr))\n",
    "\n",
    "print(str(iterative_process.initialize.type_signature))\n",
    "\n",
    "state = iterative_process.initialize()\n",
    "\n",
    "tff_train_acc = []\n",
    "tff_val_acc = []\n",
    "tff_train_loss = []\n",
    "tff_val_loss = []\n",
    "\n",
    "eval_model = None\n",
    "for round_num in range(1, NUM_ROUNDS+1):\n",
    "    state, tff_metrics = iterative_process.next(state, federated_train_data)\n",
    "    eval_model = create_keras_model()\n",
    "    eval_model.compile(optimizer=optimizers.Adam(learning_rate=client_lr),\n",
    "                       loss=losses.SparseCategoricalCrossentropy(),\n",
    "                       metrics=[metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "\n",
    "    tff.learning.assign_weights_to_keras_model(eval_model, state.model)\n",
    "#     tff.learning.set_weights(eval_model, state.model)\n",
    "\n",
    "    ev_result = eval_model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('round {:2d}, metrics={}'.format(round_num, tff_metrics))\n",
    "    print(f\"Eval loss : {ev_result[0]} and Eval accuracy : {ev_result[1]}\")\n",
    "    tff_train_acc.append(float(tff_metrics.sparse_categorical_accuracy))\n",
    "    tff_val_acc.append(ev_result[1])\n",
    "    tff_train_loss.append(float(tff_metrics.loss))\n",
    "    tff_val_loss.append(ev_result[0])\n",
    "\n",
    "metric_collection = {\"sparse_categorical_accuracy\": tff_train_acc,\n",
    "                     \"val_sparse_categorical_accuracy\": tff_val_acc,\n",
    "                     \"loss\": tff_train_loss,\n",
    "                     \"val_loss\": tff_val_loss}\n",
    "\n",
    "#if eval_model:\n",
    "#    eval_model.save(model_dir / (experiment_name + \".h5\"))\n",
    "#else:\n",
    "#    print(\"training didn't started\")\n",
    "#    exit()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plot_graph(list(range(1, 51))[4::5], tff_train_acc, label='Train Accuracy')\n",
    "plot_graph(list(range(1, 51))[4::5], tff_val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(output_dir / \"federated_model_Accuracy.png\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_graph(list(range(1, 51))[4::5], tff_train_loss, label='Train loss')\n",
    "plot_graph(list(range(1, 51))[4::5], tff_val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(output_dir / \"federated_model_loss.png\")\n",
    "\n",
    "\n",
    "\n",
    "# saving metric values to text file\n",
    "\n",
    "txt_file_path = output_dir / (experiment_name + \".txt\")\n",
    "with open(txt_file_path.as_posix(), \"w\") as handle:\n",
    "    content = []\n",
    "    for key, val in metric_collection.items():\n",
    "        line_content = key\n",
    "        val = [str(k) for k in val]\n",
    "        line_content = line_content + \" \" + \" \".join(val)\n",
    "        content.append(line_content)\n",
    "    handle.write(\"\\n\".join(content))\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efaf42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
